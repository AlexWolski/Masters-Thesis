% !TeX root = Thesis.tex

\chapter{Introduction}
\label{chap:introduction}

Recent advances in science, technology, and engineering have created a demand for efficient 3D shape reconstruction and analysis. Applications include autonomous navigation, robotics, medicine, augmented reality, and entertainment~\cite{Xiao2020, Xie2022}. These fields require methods to quickly processes 3D scenes and accurately reconstruct surfaces from sparse sensor data.

Traditional methods for 3D shape analysis require features to be manually engineered using prior knowledge of the problem. This process is not ideal as it is time consuming and overlooks potentially useful information. Research efforts have since shifted to deep learning techniques that automatically learn the most relevant features~\cite{Bengio2013}. The improved feature extraction allows deep learning models to efficiently reconstruct more complex and varied 3D geometry than is possible using traditional methods. In addition, the learned feature vectors can be applied to analysis problems such as object classification and inference of missing geometry~\cite{Park2019}.

A primary difficulty in applying deep learning to 3D reconstruction is selecting a suitable representation to describe the inputs and outputs of the network. A 3D representation must be concise enough for the network to effectively train on, yet must retain enough information to accurately reproduce the original shape. Related work employ a wide variety of 3D representations, each with unique benefits and challenges~\cite{Xiao2020}. We further discuss the different representations in the \nameref{sec:3d_representations} section of the \nameref{chap:related_work} chapter.

Recent work~\cite{Sharma2018, Kania2020, Ren2021} has explored the use of Constructive Solid Geometry (CSG) as a 3D representation. A CSG model defines a volume as a composition of simple shapes called primitives. Primitives are combined using boolean operations such as union, difference, and intersection. Each primitive is transformed using translation, rotation, and scaling operations. The selection of primitive shapes is restricted to a set of predefined manifold surfaces. Using a fixed set of high-level primitives to build shapes results in a smaller format compared to other 3D formats. By virtue of their construction, all CSG models are continuous and manifold surfaces bounding an interior volume. Additionally, editing a CSG model is convenient since each constituent primitive can be modified individually~\cite{Hughes2013}.

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Images/Union}
		\caption{Union}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Images/Difference}
		\caption{Difference}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Images/Intersect}
		\caption{Intersect}
	\end{subfigure}
	\caption{Three boolean operations applied to two spheres: (a) Union operation includes points encompassed by either sphere, (b) Difference operation includes points encompassed exclusively by the first sphere, (c) Intersect operation includes points encompassed by both spheres.}
	\label{fig:boolean operations}
\end{figure}

CSG and related primitive fitting techniques are topics of interest as they resemble Biederman's Recognition-By-Components theory~\cite{Biederman1987} for how humans comprehend 3D shapes. The theory suggests that the human brain deconstructs scenes into simple volumes called geons. Every brain is said to use the same set of 36 geon primitives to approximate complex shapes~\cite{Biederman1987}. Due to their similarity, researchers believe that the Recognition-By-Components theory sets a positive precedent for the use of CSG in deep learning~\cite{Sharma2018}.

Instead of using geons, prior work~\cite{Sharma2018, Kania2020, Ren2021} represents CSG primitives as Signed Distance Fields (SDFs). An SDF is a mathematical function that implicitly defines the surface of a volume. Given a query point, an SDF returns the shortest distance from the query point to the represented surface. This distance is positive ($+$) when the query point is outside of the volume and negative ($-$) when the query point is inside. We define the surface as the set of all input points for which the SDF returns 0 (i.e. the zero-level set). The implicit nature of SDFs results in smooth, detailed, and continuous surfaces~\cite{Park2019}. Additionally, SDFs make for good CSG primitives since applying boolean operations to distance fields is trivial.

\begin{figure}
	\centering
	\includegraphics[scale=0.2]{Images/SDF Box}
	\caption{Visualization of the SDF of a 2D box. The surface of the box is depicted in black, the exterior in green, and the interior in red. Points farther from the surface are colored darker. Each of the white isoline consist of points that are equidistant from the surface.}
	\label{fig:sdf_box}
\end{figure}

There are several benefits to using CSG models for deep 3D reconstruction. The low-dimensionality of a CSG model allows for more efficient training of the network. The continuous and watertight surfaces produced by CSG are visually pleasing. And a key benefit that most other representations lack is an easily modifiable format.

However, there are also several challenges in using a CSG representation. The first issue is the lack of uniqueness~\cite{Hughes2013}. There are multiple valid ways to construct an object using CSG. For simple objects, there is often only one construction that most accurately represents the object using the fewest primitives. This optimal construction can be used as a ground truth sample for supervised training. For complex objects, there are countless equally optimal constructions. Supervising training using just one of the possible constructions may result in poor convergence or overfitting. The second challenge is that combining geometric primitives directly without applying any blending results in sharp intersections. This is a not an issue for modeling angular surfaces. Smooth and organic surfaces, on the other hard, cannot be elegantly represented without blending primitives together.

Prior work~\cite{Sharma2018, Kania2020, Ren2021} successfully implements CSG based reconstruction algorithms using unsupervised learning. While succeeding in representing simple geometry, these works fail to incorporate primitive blending to address the poor reconstruction quality of smooth surfaces. Furthermore, these models only generate a small number of primitives. The CSG-Stump architecture~\cite{Ren2021} supports a maximum output of 256 total primitives in the paper, of which only a subset is selected for use in reconstruction. This number is sufficient to represent simple 3D shapes but fails to capture the details in more complex geometry. Although the architecture can be scaled up, the network complexity, memory requirements, and training time increase non-linearly with the output size~\cite{Ren2021}.

\begin{figure}[!b]
	\centering
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Images/Face without blending}
		\caption{Without Blending}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Images/Face with blending}
		\caption{With Blending}
	\end{subfigure}
	\caption{Demonstration of the importance of primitive blending for modeling organic shapes such as faces using CSG~\cite{Quilez2013}.}
	\label{fig:primitive_blending}
\end{figure}

To address these shortcomings, we propose the Constructive Solid Geometry Cascaded Refinement Network (CSG-CRN): a novel architecture for iteratively generating CSG reconstructions of unlimited size. This is achieved using cascaded refinement, wherein a refinement network recursively improves upon its own output. By iteratively building a reconstruction, we can achieve high reconstruction quality using a small architecture. CSG-CRN is an autoencoder network that takes point cloud inputs and predicts one SDF primitive. The Siamese encoder network generates a feature vector for both the target geometry and the current reconstruction. Then the MLP decoder network analyzes the differences in the feature vectors and generates a single SDF primitive to refine the reconstruction. The output parameters include a blending factor to better represent smooth, organic surfaces. The reconstruction can be fed back into the CSG-CRN network for an unlimited number of iterations to continue refining the reconstruction. Unlike previous work, the reconstruction time of CSG-CRN scales linearly with the level of detail. To our knowledge, this is the first approach that applies cascaded refinement to the synthesis of CSG models.

We make two main contributions in this work. First, we propose CSG-CRN, a novel architecture for generating CSG reconstructions through cascaded refinement. Second, we conduct experiments to demonstrate the following:

\begin{itemize}
	\item CSG-CRN can efficiently reconstruct a variety of known and unknown shape classes.
	\item CSG-CRN generates qualitatively and quantitatively superior reconstructions as compared to prior CSG-based work.
	\item CSG-CRN is capable of inferring missing geometry based on known shape priors.
	\item The CSG-CRN encoder produces a continuous latent space that can be interpolated.
\end{itemize}

\vspace{1em}

The outline of this paper is as follows. The next chapter, \nameref{chap:related_work}, reviews the 3D representations and neural architectures used in prior work. The \nameref{chap:background} chapter explains the mathematics of SDFs and the neural architectures used in our method. In the \nameref{chap:method} chapter, we provide a high-level view of the CSG-CRN architecture. The technical details of our implementation are provided in the \nameref{chap:implementation} chapter. The \nameref{chap:experiments_and_results} chapter contains the procedures and results for each experiment. Lastly, the \nameref{chap:conclusion} chapter summarizes our findings and discusses potential future work.
