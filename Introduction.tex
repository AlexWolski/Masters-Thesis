\chapter{Introduction}

Recent advances in science, technology, and engineering has created a demand for efficient 3D shape reconstruction and analysis. Examples of applications include autonomous navigation, robotics, medicine, augmented reality, architecture, and entertainment~\cite{Xiao2020, Xie2022}. These fields require methods to quickly comprehend 3D scenes and accurately reconstruct surfaces from sparse sensor data.

Traditional methods for 3D shape analysis involve manual feature engineering. Through this process, researchers apply prior knowledge of the problem to identify and extract relevant features from the input data. This is not an ideal solution as the processes is time consuming and overlooks many potentially useful features~\cite{Bengio2013}.

Research efforts have since shifted to machine learning techniques. Unsupervised representation learning methods are particularly well suited for analysis and reconstruction. By attempting to synthesize a given input, representation learning models automatically learn and extract the most important features for describing said input~\cite{Bengio2013}. This improved feature extraction allows representation learning models to efficiently reconstruct more complex and varied 3D geometry than is possible using traditional methods. In addition, the learned feature vectors can be used in analysis problems such as object classification and inference of missing geometry~\cite{Park2019}.

The primary difficulty in applying deep learning to 3D reconstruction is selecting a suitable 3D representation to describe the inputs and outputs of the network. A 3D representation must be concise enough for the network to efficiently train on yet be descriptive enough to accurately portray the original shape. Related works have employed a wide variety of 3D representations, each with unique benefits and challenges~\cite{Xiao2020}.

Several recent works such as~\cite{Sharma2018, Kania2020, Ren2021} have explored the use of Constructive Solid Geometry (CSG) as a 3D representation. A 3D CSG model defines a volume as a composition of simple shapes called primitives. These primitives are combined using boolean operations such as union, subtract, difference, and intersection. Each primitive is transformed into place using translation, rotation, and scaling operations. The number of different primitive shapes is restricted to a collection of predefined manifold surfaces. Using a fixed set of high-level primitives to build geometry drastically reduces file sizes compared to other 3D representations. By virtue of their construction, CSG models are guaranteed to be continuous and manifold surfaces bounding an interior volume. Additionally, editing a CSG model is easy since each constituent primitive can be individually accessed and modified.~\cite{Hughes2013}.

CSG and other primitive fitting techniques are a topics of interest as they resemble the Recognition-By-Components theory for how humans comprehend 3D shapes. This theory suggests that humans decompose scenes into simple volumes called geons. The human brain is said to use 36 geon primitives to approximate complex shapes~\cite{Biederman1987}. The theory is supported by the techniques artists use to construct human anatomy. The fist step in drawing a figure is to block out the volume using a combination of geometric and organic volumes. These shapes can range from cuboids and cylinders to ellipsoids and pear shapes~\cite{Winslow2015}. Due to the shared aspects of CSG modeling and the Recognition-By-Components theory, it is hypothesized that neural networks trained to generate CSG models will comprehend geometry in a similar manner to how humans do~\cite{Sharma2018}.

Instead of using geons, prior works~\cite{Sharma2018, Kania2020, Ren2021} represent CSG primitives as Signed Distance Fields (SDFs). An SDF is a mathematical function that implicitly defines the surface of a volume. Given a query point, the SDF returns the shortest distance between the query point and the represented surface. This distance is positive ($+$) when the query point is outside of the volume and negative ($-$) when the query point is inside. We define the surface as the set of all input points for which the SDF returns 0 (i.e. the zero-level set). The implicit nature of SDFs results in smooth, detailed, and continuous surfaces~\cite{Park2019}. Additionally, SDFs make for good CSG primitives since applying boolean operations to mathematical functions is trivial.

There are several benefits to using CSG models for deep 3D reconstruction. The low-dimensionality of a CSG model allows for more efficient training of the network. The continuous and watertight surfaces produced by CSG are visually pleasing. And a key benefit that most other representations lack is an easily modifiable format.

However, there are also several challenges in using this representation. The first issue is the lack of uniqueness in a CSG model~\cite{Hughes2013}. Since there are multiple valid ways to reconstruct a volume using CSG, a network cannot be supervised using expected output samples. Secondly, directly combining geometric primitives without applying any blending results in sharp corners and edges. This is a not an issue when modeling angular mechanical components. Smooth and organic surfaces, on the other hard, cannot be elegantly represented without blending primitives together.

Previous works~\cite{Sharma2018, Kania2020, Ren2021} have successfully implemented CSG based reconstruction algorithms using unsupervised learning. But these works fail to incorporate primitive blending to address the poor reconstruction quality of smooth surfaces. Furthermore, these works only generate a relatively small number of primitives. The CSG-Stump architecture~\cite{Ren2021} supports a maximum output of 256 total primitives in the paper, not all primitives are used at once. This number is sufficient to represent simple 3D shapes but fails to capture the details in more complex geometry. While the architecture can be scaled up, the network complexity and training time rises non-linearly with the output size.

To address these shortcomings in prior works, we propose Iter-CSG Net: a novel architecture for iteratively generating CSG reconstructions of unlimited size. By building the reconstruction through cascaded refinement, the architecture can be kept small without sacrificing reconstruction quality. Iter-CSG is an autoencoder network that takes point clouds as input and outputs SDF primitives. The Siamese encoder generates a feature vector for both the target geometry and the current reconstruction. Then the GRU decoder analyzes the differences in the feature vectors and generates multiple SDF primitives to refine the reconstruction. The output parameters include a blending factor for each primitive to better represent organic and smooth surfaces. To further refine the reconstruction, the output can be fed back into the Iter-CSG network to generate additional primitives. Unlike previous works, the computation time scales linearly with the level of detail. To our knowledge, this is the first approach that applies cascaded refinement to the reconstruction of 3D surfaces.

We make two contributions in this work. Firstly, we propose Iter-CSG, a novel architecture for generating CSG reconstructions through cascaded refinement. Secondly, we conduct experiments to test the following statements:

\begin{itemize}
	\item Iter-CSG can efficiently reconstruct a variety of known and unknown shape classes.
	\item Iter-CSG can generate qualitatively and quantitatively superior reconstructions than all prior CSG-based reconstruction networks.
	\item The Iter-CSG encoder network is capable of inferring missing geometry based on known shape priors.
	\item The Iter-CSG encoder produces a continuous latent space that can be interpolated.
\end{itemize}