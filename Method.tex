% !TeX root = Thesis.tex

\chapter{Method}
\label{chap:method}

This chapter presents the architecture of CSG-CRN.


\section{Input~Shape~Representation}
\label{sec:input_shape_representation}

CSG-CRN takes SDF point clouds as input. The format consists a set of query points in $\mathbb{R}^3$ and the corresponding signed distance value to the represented surface. This format was chosen to facilitate an efficient and differentiable method of discretizing implicit SDFs. Since CSG-CRN is a cascaded refinement network, the implicit SDF output is discretized and reused as an input to the network.


\section{Encoder~Network}
\label{sec:encoder_network}

A Siamese encoder network is used to extract features from an initial reconstruction input and a target shape input. The Siamese encoder is comprised of two separate encoder networks that share weights. The two feature vectors produced by the Siamese encoder are processed by a contrastive encoder network to find the difference between the reconstruction and target shapes.

\section{CSG-Primitive~Prediction}
\label{sec:csg_primitive_prediction}

To predict a CSG primitive, we optimize for the function
\[f_\theta (X, Y) = (p, s, t, q, \alpha, \gamma).\]
We optimize the network parameters $\theta$, given an input point cloud$X$ and initial reconstruction point cloud $Y$. The model predicts the parameters of a primitive: primitive shape $p$, scale $s$, translation $t$, quaternion rotation $q$, blending factor $\alpha$, and boolean operation $\gamma$.


\section{CSG-To-SDF~Conversion}
\label{sec:csg_to_sdf_conversion}

Each primitive is represented by an SDF function. We can apply boolean operations to the primitive SDF functions to build a complete SDF function. The union of SDF functions $A$ and $B$ is computed as $min(A, B)$. A subtracted from B is computed as $min(-A, B)$. And the intersect of A and B is computed as $max(A, B)$.

To complete the refined CSG reconstruction, we combine the predicted primitive with the initial reconstruction SDF function using the predicted boolean operation. The refined reconstruction SDF can then sampled to compute the loss.


\section{Reconstruction~Loss}
\label{sec:reconstruction_loss}

We use the DeepSDF loss function to compute the reconstruction error between a target and a reconstruction point cloud. The DeepSDF loss function uses an L1 loss function with clamped SDF values
\[\Loss_{\surface}=\Loss_1(\clamp(\SDF(X)), \clamp(\SDF(Y))),\]
where $\clamp(x)$ is defined as $\max(-\delta, \min(\delta, x))$ for a clamping size $\delta$. We choose this loss function because it focuses the network on surface reconstruction quality. With clamping, the network would tend to minimize the average distance to the predicted primitive over all points. Unlike in DeepSDF, we uniformly sample points in a volume around the input shape. This makes it unlikely for points to be on the clamping boundary, which is not differentiable.

Because the loss function is clamped, the gradient is zero for primitives far from the object surface. We use an auxiliary loss from CSGStump to draw primitives to the reconstruction surface
\[\Loss_{\primitive} = \frac{1}{K} \sum_{k}^{K} \min ( \SDF_k^2(x_n) ).\]
The combined loss function is
\[\Loss_{\total} = \Loss_{\surface} + \Loss_{\primitive}.\]


\section{Cascaded~Refinement}
\label{sec:cascaded_refinement}

Once we have refined the reconstruction, we can sample another point cloud from the reconstruction and feed it back into the network. We again uniformly sample the SDF function.


\section{Training}
\label{sec:training}

We use a progressive training method inspired by Curriculum DeepSDF. In the first phase, all the initial reconstructions are empty. We represent this by representing the initial reconstruction as a single point at the origin. After training for a set number of epochs, we synthesize refined reconstructions and add them to the dataset. The second phase will randomly select samples from the initial and synthesized datasets. This process continues until the reconstructions reach a threshold accuracy. With this scheme, we train the model to refine partial reconstruction. And model can learn more efficiently by starting with easier samples and progressing to harder ones.
